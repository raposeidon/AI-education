{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Yu1j3jYmfvlZ"
      ],
      "history_visible": true,
      "gpuType": "T4",
      "mount_file_id": "1WVHhJ9vEbejaKiIBjkfQZpSYtLF3PZKB",
      "authorship_tag": "ABX9TyPe5qfavKuxHWq/vYcIN/8H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raposeidon/AI-education/blob/main/colabs/LLAMA_pretrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAKFUKP_TPJl"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate sentencepiece datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "Xr-Okeilc-aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "raw_dataset = load_dataset('ccdv/cnn_dailymail', '3.0.0')"
      ],
      "metadata": {
        "id": "d7Ep1L2ZdWCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset['train'][0]['article'][:200]"
      ],
      "metadata": {
        "id": "Xk5KApDOdyKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset['train'].to_pandas()"
      ],
      "metadata": {
        "id": "E5nYhPLoiVwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_dataset = DatasetDict(\n",
        "    {\n",
        "        \"train\": raw_dataset['train'].select(range(50000)).shuffle(),\n",
        "        \"valid\": raw_dataset['test'].select(range(5000)).shuffle()\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "0MubpWUnfDRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **tokenizer**"
      ],
      "metadata": {
        "id": "Yu1j3jYmfvlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
        "tokenizer"
      ],
      "metadata": {
        "id": "GUvxrEREfDFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_corpus(ds):\n",
        "  return(\n",
        "      ds[i:i+1000]['article'] for i in range(0, len(ds), 1000)\n",
        "  )\n",
        "\n",
        "training_corpus = get_training_corpus(raw_dataset['train'])"
      ],
      "metadata": {
        "id": "--RKxU1fgaal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "tokenizer = tokenizer.train_new_from_iterator(training_corpus, vocab_size=50527)"
      ],
      "metadata": {
        "id": "XW7nzmerg8-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria.\"\n",
        "\n",
        "tokenizer.tokenize(sample_text)"
      ],
      "metadata": {
        "id": "ZBf98qvhhxrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(sample_text)\n",
        "#tokenizer(sample_text, return_length=True)"
      ],
      "metadata": {
        "id": "_q0F1gDT3CEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = 128\n",
        "\n",
        "def tokenize(batch):\n",
        "  outputs = tokenizer(\n",
        "      batch['article'],\n",
        "      max_length=context_length,\n",
        "      truncation=True,\n",
        "      return_overflowing_tokens=True,\n",
        "      return_length=True\n",
        "  )\n",
        "\n",
        "  input_batch = []\n",
        "  for length, input_ids in zip(outputs['length'], outputs['input_ids']):\n",
        "    if length==context_length:\n",
        "      input_batch.append(input_ids)\n",
        "  return {\"input_ids\":input_batch}"
      ],
      "metadata": {
        "id": "kDmTRSNn3IoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = sampled_dataset.map(tokenize, batched=True, remove_columns=raw_dataset['train'].column_names)"
      ],
      "metadata": {
        "id": "LeQjJo3Z4Q2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **load_model**"
      ],
      "metadata": {
        "id": "rZcHNya_5489"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LlamaConfig\n",
        "\n",
        "configuration = LlamaConfig()\n",
        "\n",
        "configuration"
      ],
      "metadata": {
        "id": "dSzN3mEf57qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.bos_token_id, tokenizer.eos_token_id, tokenizer.vocab_size"
      ],
      "metadata": {
        "id": "DK0RBia06h0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configuration = LlamaConfig (**{\n",
        "  \"attention_bias\": False,\n",
        "  \"bos_token_id\": 50256,\n",
        "  \"eos_token_id\": 50256,\n",
        "  \"hidden_act\": \"silu\",\n",
        "  \"hidden_size\": 512,\n",
        "  \"initializer_range\": 0.02,\n",
        "  \"intermediate_size\": 1376,\n",
        "  \"max_position_embeddings\": 128,\n",
        "  \"model_type\": \"llama\",\n",
        "  \"num_attention_heads\": 4,\n",
        "  \"num_hidden_layers\": 4,\n",
        "  \"num_key_value_heads\": 4,\n",
        "  \"pretraining_tp\": 1,\n",
        "  \"rms_norm_eps\": 1e-06,\n",
        "  \"rope_scaling\": None,\n",
        "  \"rope_theta\": 10000.0,\n",
        "  \"tie_word_embeddings\": False,\n",
        "  \"transformers_version\": \"4.35.0\",\n",
        "  \"use_cache\": True,\n",
        "  \"vocab_size\": 50257\n",
        "})"
      ],
      "metadata": {
        "id": "_zXNNEEL6vsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LlamaForCausalLM\n",
        "\n",
        "model = LlamaForCausalLM(configuration)\n",
        "model"
      ],
      "metadata": {
        "id": "WRCf15I-7iB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "4_8f-dGc71m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "0"
      ],
      "metadata": {
        "id": "A2FOmzQc8GP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in \"\n",
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "inputs.to(device)\n",
        "\n",
        "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
        "generate_ids"
      ],
      "metadata": {
        "id": "Ap4ISFvu8PQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
      ],
      "metadata": {
        "id": "TKmzhC-Q8PGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train **model**"
      ],
      "metadata": {
        "id": "zs5Wa10u8-u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
      ],
      "metadata": {
        "id": "uz29TEzs9B_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = data_collator([tokenized_datasets['train'][i] for i in range(3)])\n",
        "\n",
        "for key in out:\n",
        "  print(f\"{key}: {out[key].shape}\")"
      ],
      "metadata": {
        "id": "Mtg-Ivll9nxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out['input_ids'][0][:20], out['attention_mask'][0][:20], out['labels'][0][:20]"
      ],
      "metadata": {
        "id": "T-Z8sSoC-psC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L4lqhPLL-pqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "batch_size = 32\n",
        "logging_steps = 1000\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 1\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir='newsllama',\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps=logging_steps,\n",
        "    save_steps=logging_steps,\n",
        "    gradient_accumulation_steps=8,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.1,\n",
        "    warmup_steps=logging_steps,\n",
        "    lr_scheduler_type='cosine',\n",
        "    learning_rate=5e-4,\n",
        "    fp16=True,\n",
        "    push_to_hub=False\n",
        ")"
      ],
      "metadata": {
        "id": "19olJg_D-pnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['valid'],\n",
        ")"
      ],
      "metadata": {
        "id": "wKbTEEeO-paz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "dNXPOq2-A7Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in \"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "inputs.to(\"cuda:0\")\n",
        "\n",
        "generate_ids = model.generate(inputs.input_ids, max_length=128)\n",
        "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
      ],
      "metadata": {
        "id": "659a9kfQKXlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('daily_llama_1106')\n",
        "tokenizer.save_pretrained('daily_tokenizer_1106')"
      ],
      "metadata": {
        "id": "TwmP6QAyL6kW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}